{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62064952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6951cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001EB191C2900> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001EB191C3380> root_client=<openai.OpenAI object at 0x000001EB19051BE0> root_async_client=<openai.AsyncOpenAI object at 0x000001EB191C2A50> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "content='I’m ChatGPT, powered by OpenAI’s GPT-4 architecture. This large language model enables me to understand and respond to a wide variety of questions and topics. How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 244, 'prompt_tokens': 20, 'total_tokens': 264, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_7989eaacf6', 'id': 'chatcmpl-BakgEO4Hbyy40UdY4eOZix2ZSiPJQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--3e7cae03-6ea3-4771-9fe7-829d3a3487b2-0' usage_metadata={'input_tokens': 20, 'output_tokens': 244, 'total_tokens': 264, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}\n",
      "I’m ChatGPT, powered by OpenAI’s GPT-4 architecture. This large language model enables me to understand and respond to a wide variety of questions and topics. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='o1-mini')\n",
    "print(llm)\n",
    "result = llm.invoke('what is the llm model you used to answer this query')\n",
    "print(result)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a27564f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x000001EB2311CF50> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001EB2311CB90> model_name='qwen-qwq-32b' model_kwargs={} groq_api_key=SecretStr('**********')\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking, \"What best you can do for me.\" I need to figure out the best way to respond. Let me start by understanding the user's intent. They might be looking for assistance or information, and they want to know what I can specifically offer. \n",
      "\n",
      "First, I should list out the main capabilities I have as a language model. I can answer questions, explain concepts, help with creative tasks like writing stories or emails, provide advice on various topics, solve problems, and maybe even assist with coding. But I should present these in a structured way.\n",
      "\n",
      "Wait, the user might be in a hurry or just curious. I should make sure my response is clear and covers all the key areas without being too technical. Maybe start with a general statement about being a versatile assistant, then break it down into categories like answering questions, creative writing, problem-solving, learning, etc. \n",
      "\n",
      "Hmm, also, I should mention that my capabilities are language-based, so I can't do things that require physical interaction or real-time data beyond what's available up to my knowledge cutoff. Oh, and maybe emphasize that I can help in a wide range of areas, giving examples for each category. \n",
      "\n",
      "Let me make sure to structure it so each point is a bullet point or a numbered list for clarity. But since the user's response needs to be in a single message, I should present it in a concise and friendly manner. \n",
      "\n",
      "Wait, the user's query is a bit open-ended. They might need more specific help, so offering examples could be useful. Maybe after outlining my abilities, I can invite them to ask a specific question or request a task. That way, they know to give more details if needed. \n",
      "\n",
      "Also, I should avoid jargon and keep the tone helpful and approachable. Let me double-check if there are any other areas I should mention. Maybe translations, summarizing information, or assisting with logical reasoning. Yeah, those are important points too. \n",
      "\n",
      "Alright, putting it all together: start with a friendly acknowledgment, list the key areas with brief explanations, and end by inviting them to ask for help. Make sure it's easy to read and covers the main points without overwhelming the user.\n",
      "</think>\n",
      "\n",
      "I'm here to help with a wide range of tasks and questions! Here’s what I can assist you with best:\n",
      "\n",
      "1. **Answering Questions**:  \n",
      "   - Clarify concepts, explain complex topics (e.g., science, history, tech), or provide factual information up to December 2024.\n",
      "\n",
      "2. **Creative Writing**:  \n",
      "   - Draft stories, emails, scripts, or creative content. I can even simulate writing styles (e.g., Shakespearean, poetic).\n",
      "\n",
      "3. **Problem-Solving**:  \n",
      "   - Help with math, logic puzzles, coding logic, or brainstorming solutions to real-world challenges.\n",
      "\n",
      "4. **Learning Support**:  \n",
      "   - Explain topics for school/college subjects, provide study tips, or suggest resources for learning new skills.\n",
      "\n",
      "5. **Language and Translation**:  \n",
      "   - Translate text between multiple languages, check grammar, or refine writing for clarity and tone.\n",
      "\n",
      "6. **Advice and Perspectives**:  \n",
      "   - Offer insights on personal growth, career decisions, or ethical dilemmas (though I’m not a professional advisor).\n",
      "\n",
      "7. **Fun and Entertainment**:  \n",
      "   - Play word games, suggest books/movies, or help brainstorm ideas for hobbies or projects.\n",
      "\n",
      "8. **Logical Reasoning**:  \n",
      "   - Assist with critical thinking, debate prep, or analyzing arguments.\n",
      "\n",
      "---\n",
      "\n",
      "### How can I help you today?  \n",
      "Let me know what you need, and I’ll do my best to provide tailored assistance!\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model='qwen-qwq-32b')\n",
    "print(llm)\n",
    "\n",
    "response = llm.invoke('What best you can do for me')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa7bebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are a expert health care specialist'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a expert health care specialist\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36b44308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are a expert health care specialist'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001EB2311CF50>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001EB2311CB90>, model_name='qwen-qwq-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=prompt|llm\n",
    "chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "674c800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, the user is asking about healthy blood pressure levels. Let me start by recalling the standard guidelines. The American Heart Association classifies blood pressure into different categories. First, I need to make sure I have the latest numbers right. As of recent guidelines, normal blood pressure is less than 120/80 mmHg. But wait, sometimes there are updates, so I should double-check that. Maybe there was a change a few years back?\n",
      "\n",
      "Hmm, I think the 2017 ACC/AHA guidelines still stand. So, the categories are: \n",
      "\n",
      "- **Normal**: Systolic <120 and Diastolic <80\n",
      "- **Elevated**: Systolic 120-129 and Diastolic <80\n",
      "- **Hypertension Stage 1**: 130-139 over 80-89\n",
      "- **Hypertension Stage 2**: ≥140 over ≥90\n",
      "- **Hypertensive Crisis**: ≥180 over ≥120, which requires immediate attention.\n",
      "\n",
      "Wait, the user just wants the healthy levels, so focusing on Normal and maybe Elevated as a borderline. I should explain each part clearly. Also, mention that individual variations exist. Factors like age, overall health, and other conditions might affect what's considered healthy for a person. \n",
      "\n",
      "I should also note that consistent readings are important. A single reading isn't enough. Lifestyle factors like diet, exercise, and stress management play a role in maintaining healthy BP. Maybe add a brief explanation of systolic and diastolic pressures for clarity, since not everyone might know the difference.\n",
      "\n",
      "Oh, and the user might be checking their own BP or a loved one's. It's important to advise consulting a healthcare provider for personalized advice, especially if they're concerned about their readings. Also, mention that even if someone is in the normal range, leading a healthy lifestyle is key to prevention. \n",
      "\n",
      "Wait, should I mention the \"hypertensive crisis\" part? The user asked for healthy levels, but including the crisis stage as a contrast might be helpful for context. But maybe keep it concise. \n",
      "\n",
      "Let me structure the answer step by step: first the normal range, then the other categories briefly, factors affecting BP, and lifestyle tips. Make sure to use clear definitions and avoid jargon. Also, emphasize the importance of regular monitoring and professional consultation.\n",
      "</think>\n",
      "\n",
      "Certainly! Here’s a clear breakdown of healthy blood pressure (BP) levels and related categories according to current medical guidelines (American Heart Association/American College of Cardiology):\n",
      "\n",
      "---\n",
      "\n",
      "### **Healthy Blood Pressure Ranges**  \n",
      "**Normal BP**:  \n",
      "- **Systolic (top number)**: <120 mmHg  \n",
      "- **Diastolic (bottom number)**: <80 mmHg  \n",
      "\n",
      "This range is **ideal for adults** and indicates a low risk of cardiovascular disease.  \n",
      "\n",
      "---\n",
      "\n",
      "### **Other Key Categories**  \n",
      "1. **Elevated BP**:  \n",
      "   - Systolic: 120–129 mmHg  \n",
      "   - Diastolic: <80 mmHg  \n",
      "   - This is a warning sign to adopt healthier habits (e.g., diet, exercise).  \n",
      "\n",
      "2. **Hypertension (High BP)**:  \n",
      "   - **Stage 1**: 130–139 / 80–89 mmHg  \n",
      "   - **Stage 2**: ≥140 / ≥90 mmHg  \n",
      "   - Requires medical evaluation and management (lifestyle changes + possible medication).  \n",
      "\n",
      "3. **Hypertensive Crisis**:  \n",
      "   - ≥180 / ≥120 mmHg  \n",
      "   - **Seek immediate medical care** (may indicate organ damage).  \n",
      "\n",
      "---\n",
      "\n",
      "### **Important Notes**  \n",
      "- **Individual Variations**: Some people may have naturally lower or higher baseline BP, but these categories are evidence-based averages.  \n",
      "- **Consistency Matters**: A single reading isn’t conclusive. BP can fluctuate daily. A diagnosis requires consistent measurements.  \n",
      "- **Lifestyle Factors**:  \n",
      "  - **Healthy habits** (exercise, low-salt diet, limited alcohol, stress management) help maintain normal BP.  \n",
      "  - Smoking, obesity, and chronic conditions (e.g., diabetes) can elevate BP.  \n",
      "\n",
      "---\n",
      "\n",
      "### **What Do the Numbers Mean?**  \n",
      "- **Systolic Pressure** (top number): Force in arteries when the heart beats.  \n",
      "- **Diastolic Pressure** (bottom number): Pressure when the heart rests between beats.  \n",
      "\n",
      "---\n",
      "\n",
      "### **When to See a Doctor**  \n",
      "- If readings consistently fall in the **elevated or hypertension stages**, consult a healthcare provider.  \n",
      "- Even within the \"normal\" range, chronic conditions or symptoms (dizziness, chest pain) warrant evaluation.  \n",
      "\n",
      "Always prioritize personalized advice from a healthcare professional, as they can address your unique health profile.  \n",
      "\n",
      "Let me know if you need further clarification!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chain.invoke({\"input\":\"can you tell me healthy person BP levels\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5454b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, the user is asking about normal blood sugar levels after a meal. Let me start by recalling the standard ranges. I know that blood sugar levels can vary depending on when someone last ate. The key here is postprandial, which means after eating. \n",
      "\n",
      "First, I should mention the typical range for a 2-hour postprandial test. From what I remember, the normal range is usually under 140 mg/dL (7.8 mmol/L) two hours after eating. That's the standard for someone without diabetes. But I should also note that this can vary slightly between different sources, so I need to be precise.\n",
      "\n",
      "Wait, maybe I should also include the fasting levels for context, just to make sure the user understands the difference. Fasting is usually under 100 mg/dL, right? But the question is about after a meal, so maybe that's secondary. Still, a brief mention could be helpful.\n",
      "\n",
      "I should also consider the different guidelines from organizations like the American Diabetes Association. They might have specific cutoffs. Also, prediabetes and diabetes have different thresholds. For example, if someone has 140-199 mg/dL two hours after eating, that's prediabetes, and above 200 mg/dL might indicate diabetes. But the user is asking for normal, so I need to highlight the normal range first.\n",
      "\n",
      "Are there any other time points? Like 1 hour after eating? Some sources mention that 1-hour levels can be higher but should drop by two hours. However, standard testing is usually at two hours. Maybe mention that the two-hour mark is the standard for diagnosis.\n",
      "\n",
      "Also, it's important to note that individual variations exist. Factors like the type of food consumed, portion size, and personal metabolism can affect the readings. But the standard guidelines are based on the two-hour mark post-meal.\n",
      "\n",
      "Let me check if there's any confusion between fasting and postprandial. The user might be comparing, but the question is clear. I should structure the answer by stating the normal range, then explain the context, maybe mention the diagnostic criteria for prediabetes and diabetes, and add a note about factors influencing levels.\n",
      "\n",
      "Wait, units are important. The user didn't specify, but in the US, mg/dL is common, while mmol/L is used in other countries. Including both would be helpful. So I'll present both units.\n",
      "\n",
      "Also, maybe a summary table would be useful, but since it's text-based, I'll format it clearly. Let me structure it step by step: normal range, prediabetes, diabetes, and mention the time frame (two hours after the start of the meal). \n",
      "\n",
      "I should also advise consulting a healthcare provider for personalized advice, as individual situations can vary. Emphasize that these are general guidelines and not a substitute for medical testing.\n",
      "\n",
      "Double-checking the numbers: ADA states that 2 hours after eating, the blood sugar should be less than 140 mg/dL (7.8 mmol/L) for normal. 140-199 mg/dL (7.8-11.0 mmol/L) is prediabetes, and 200+ (11.1+) is diabetes. That's correct. \n",
      "\n",
      "So putting it all together, the answer should be clear and concise, giving the ranges with units, explaining the time frame, and noting when to seek further evaluation. Make sure to avoid jargon and keep it understandable.\n",
      "</think>\n",
      "\n",
      "Normal blood sugar levels after a meal (postprandial) are measured two hours after the start of eating. Here's the general guideline:\n",
      "\n",
      "### **Normal Range (Non-Diabetic):**\n",
      "- **2 hours after a meal**: **Less than 140 mg/dL (7.8 mmol/L)**\n",
      "\n",
      "### **Context & Key Details:**\n",
      "1. **Fasting vs. Postprandial**: \n",
      "   - Fasting blood sugar (after 8+ hours without food): **70–99 mg/dL (3.9–5.5 mmol/L)**.\n",
      "   - After eating, levels rise temporarily but should return to near-fasting levels within 2 hours.\n",
      "\n",
      "2. **Prediabetes & Diabetes Criteria (per American Diabetes Association):**\n",
      "   | **Condition**       | **2-Hour Postprandial Blood Sugar**       |\n",
      "   |----------------------|--------------------------------------------|\n",
      "   | **Normal**           | <140 mg/dL (7.8 mmol/L)                    |\n",
      "   | **Prediabetes**      | 140–199 mg/dL (7.8–11.0 mmol/L)           |\n",
      "   | **Diabetes**         | ≥200 mg/dL (11.1 mmol/L)                   |\n",
      "\n",
      "3. **Important Notes:**\n",
      "   - **Timing**: The measurement is taken 2 hours after the first bite of a meal.\n",
      "   - **Individual Variation**: Factors like carbohydrate intake, insulin sensitivity, and metabolism can influence results.\n",
      "   - **Testing**: Diagnosis of diabetes or prediabetes requires confirmation with follow-up tests (e.g., A1C test or repeat glucose testing).\n",
      "\n",
      "### **When to Seek Evaluation:**\n",
      "- Consistent readings ≥140 mg/dL (7.8 mmol/L) at 2 hours may indicate prediabetes or diabetes.\n",
      "- Consult a healthcare provider for personalized advice if you’re concerned about blood sugar levels, have symptoms like excessive thirst/fatigue, or have risk factors (family history, obesity, sedentary lifestyle).\n",
      "\n",
      "Always confirm with a healthcare professional for accurate interpretation and management.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "outputparser = StrOutputParser()\n",
    "\n",
    "chain = prompt|llm|outputparser\n",
    "\n",
    "response = chain.invoke(\"what is the normal blood sugar levels of human after meal\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65881c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "outputparser = JsonOutputParser()\n",
    "\n",
    "outputparser.get_format_instructions()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fea33502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'Return a JSON object.'}, template='Respond to the user query below. Give the final answer only.Provide the result without reasoning.Output only the answer.Your response MUST be a JSON object that follows the format instructions. Do NOT include any other text or explanation outside the JSON object. Do not give the think description in the output.\\n{format_instructions}\\nUser Query: {query}')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"answer the user query \\n {format_instructions} n {query}\\n\",\n",
    "#     input_varaiables=[\"query\"],\n",
    "#     partial_variables={\"format_instructions\": outputparser.get_format_instructions()},\n",
    "#     )\n",
    "\n",
    "# prompt\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Respond to the user query below. Give the final answer only.Provide the result without reasoning.Output only the answer.Your response MUST be a JSON object that follows the format instructions. Do NOT include any other text or explanation outside the JSON object. Do not give the think description in the output.\\n{format_instructions}\\nUser Query: {query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": outputparser.get_format_instructions()},\n",
    " )\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ad6aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x000001EB22AAF6F0> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001EB22AAFBB0> model_name='gemma2-9b-it' model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(model='gemma2-9b-it')\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb3cbaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x000001EB22AAD0F0> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001EB22AAC180> model_name='gemma2-9b-it' model_kwargs={} groq_api_key=SecretStr('**********')\n",
      "content='{\"blood_sugar_level\": \"70-140 mg/dL\"}' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 90, 'total_tokens': 110, 'completion_time': 0.036363636, 'prompt_time': 0.004183373, 'queue_time': 0.24397269500000002, 'total_time': 0.040547009}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--d04ca1dd-1537-4731-9f33-d3ad178064c8-0' usage_metadata={'input_tokens': 90, 'output_tokens': 20, 'total_tokens': 110}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "response = chain.invoke({\"query\":\"what is the normal blood sugar levels of human after meal\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13081a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': '70-120 mg/dL'}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm|outputparser\n",
    "response = chain.invoke({\"query\":\"what is the normal blood sugar levels of human after meal\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9d123f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are a expert health care specialist, provide response as json object.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a expert health care specialist, provide response as json object.\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5c40e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal_blood_sugar_levels_after_meal': {'adult': {'2 hours after eating': '70 to 140 mg/dL'}, 'child': {'2 hours after eating': 'less than 180 mg/dL'}, 'note': 'Blood sugar levels can vary depending on individual factors and the type of food consumed.'}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm|outputparser\n",
    "response = chain.invoke({\"input\":\"what is the normal blood sugar levels of human after meal\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25c98d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"you are a expert health care specialist, provide response as XML object. Don't add any extra text other than XML\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a expert health care specialist, Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc491e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<response>\\n  <normal_blood_sugar_after_meal>\\n    70 to 140 mg/dL\\n  </normal_blood_sugar_after_meal>\\n</response>' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 44, 'total_tokens': 106, 'completion_time': 0.112727273, 'prompt_time': 0.003382743, 'queue_time': 0.251699485, 'total_time': 0.116110016}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--0123bd92-c910-4bc0-8dcb-2a5869cc652e-0' usage_metadata={'input_tokens': 44, 'output_tokens': 62, 'total_tokens': 106}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "outputparser = XMLOutputParser()\n",
    "\n",
    "chain = prompt|llm\n",
    "response = chain.invoke({\"input\":\"what is the normal blood sugar levels of human after meal\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e9af5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 1)) (2.11.5)\n",
      "Requirement already satisfied: python-dotenv in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: langchain in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 3)) (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 4)) (0.3.18)\n",
      "Requirement already satisfied: langchain-groq in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 5)) (0.3.2)\n",
      "Requirement already satisfied: langchain-core in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 6)) (0.3.61)\n",
      "Requirement already satisfied: langchain-community in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 7)) (0.3.24)\n",
      "Collecting defusedxml (from -r ../requirements.txt (line 8))\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 1)) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 3)) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 3)) (0.3.42)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 3)) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-core->-r ../requirements.txt (line 6)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-core->-r ../requirements.txt (line 6)) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-core->-r ../requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->-r ../requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (0.23.0)\n",
      "Requirement already satisfied: anyio in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: certifi in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r ../requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r ../requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r ../requirements.txt (line 3)) (3.2.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-openai->-r ../requirements.txt (line 4)) (1.82.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-openai->-r ../requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai->-r ../requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai->-r ../requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai->-r ../requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai->-r ../requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai->-r ../requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-groq->-r ../requirements.txt (line 5)) (0.25.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-community->-r ../requirements.txt (line 7)) (3.11.18)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-community->-r ../requirements.txt (line 7)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-community->-r ../requirements.txt (line 7)) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-community->-r ../requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: numpy>=2.1.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from langchain-community->-r ../requirements.txt (line 7)) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 7)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 7)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 7)) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 7)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 7)) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r ../requirements.txt (line 7)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r ../requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\d_drive\\dataworld\\data_science\\genai\\agentic_ai_gen_ai_course\\agenticai\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r ../requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lskir\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai->-r ../requirements.txt (line 4)) (0.4.6)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: defusedxml\n",
      "Successfully installed defusedxml-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f47dd2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"query\": {\"description\": \"Patient query\", \"title\": \"Query\", \"type\": \"string\"}, \"response\": {\"description\": \"Health expert answer\", \"title\": \"Response\", \"type\": \"string\"}}, \"required\": [\"query\", \"response\"]}\\n```'}, template='Answer the user query.\\n{format_instructions}\\n{query}\\n')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your desired data structure.\n",
    "from pydantic import BaseModel, Field\n",
    "class HealthAdvice(BaseModel):\n",
    "    query: str = Field(description=\"Patient query\")\n",
    "    response: str = Field(description=\"Health expert answer\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=HealthAdvice)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8806859c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"query\": {\"description\": \"Patient query\", \"title\": \"Query\", \"type\": \"string\"}, \"response\": {\"description\": \"Health expert answer\", \"title\": \"Response\", \"type\": \"string\"}}, \"required\": [\"query\", \"response\"]}\\n```'}, template='Answer the user query.\\n{format_instructions}\\n{query}\\n')\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001EB22AAF6F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001EB22AAFBB0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| JsonOutputParser(pydantic_object=<class '__main__.HealthAdvice'>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "469a3db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'when to take paracetamol',\n",
       " 'response': \"Paracetamol is a common over-the-counter pain reliever and fever reducer. It's generally safe for adults and children when taken as directed. However, it's important to consult with a doctor or pharmacist before taking paracetamol, especially if you have any underlying health conditions or are taking other medications. They can advise on the appropriate dosage and potential interactions.  Remember to always follow the instructions on the product label.\"}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"query\":\"when to take paracetamol\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a1438d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Give me details about office chair',\n",
       " 'response': 'An office chair is a type of chair specifically designed for use at a desk.  \\n\\n **Product Name:** Ergonomic Office Chair\\n **Details:**  Features adjustable height, lumbar support, breathable mesh back, and padded armrests for comfort and support during long work hours. \\n **Price:** $250'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class ProductInfo(BaseModel):\n",
    "    query: str = Field(description=\"product enquiry from the customer\")\n",
    "    response: str = Field(description=\"Product details from the product vendor\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=HealthAdvice)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query and must include product name, product details and also product tentative price in USD ( integer) \\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\":\"Give me details about office chair\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc4efb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
